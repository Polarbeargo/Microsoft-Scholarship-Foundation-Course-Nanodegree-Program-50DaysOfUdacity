# Microsoft-Scholarship-Foundation-course-Nanodegree-Program
50DaysOfUdacity 

[image1]: ./images/score.png    
[image2]: ./images/evaluate.png  

Participation in the Microsoft Scholarship Foundation course Nanodegree Program 50 days of Udacity challenge

Follow Udacity Git Commit Message Style Guide: https://udacity.github.io/git-styleguide/  

### Day 1 : 14/07/2020 
#### Polarbeargo 

* Reading Lesson 2 Introduction to Machine Learning section 20 Linear Regression.
* I very love the Text data section where I have chance to read how to process text data with normalization(Lemmatization, Tokenization) and Vectorization where 
  I got understand about:
    * Term Frequency-Inverse Document Frequency (TF-IDF) vectorization
    * Word embedding, as done with Word2vec or Global Vectors (GloVe)
* Section 8 Scaling data with Standardization and Normalization where I'm very glad that I have chance to read this section :)

### Day 2 : 15/07/2020 
#### Polarbeargo 

* Reanding Lesson 2 Introduction to Machine Learning section 20 Linear Regression grasp the following concepts to talk to:
  * "To train a linear regression model" means to learn the coefficients and bias that best fit the data. 
  * The process of finding the best model is essentially a process of finding the coefficients and bias that minimize this error. 
  * Preparing the Data:  
        * Linear assumption  
        * Remove collinearity  
        * Gaussian (normal) distribution  
        * Rescale data  
        * Remove noise    
  * Calculating the Coefficients: Choose a cost function (like RMSE) to calculate the error and then minimize that error in order to arrive at a line of best fit that models the training data and can be used to make predictions.  
* Writing Quiz "Linear Regression: Check Your Understanding".

### Day 3 : 16/07/2020 
#### Polarbeargo

* Reading  Lesson 2 Introduction to Machine Learning section 23 lab Instruction and writing section 24 lab: Train a Linear Regression Model:  

Score Model      |  Evaluate Model
:-------------------------:|:-------------------------:
![][image1]                | ![][image2]
